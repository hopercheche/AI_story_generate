# AI Story Generator / AI çˆ†æ¬¾å°è¯´ç”Ÿæˆå™¨

[English](#english) | [ä¸­æ–‡](#chinese)

<a name="english"></a>
## ğŸ“– Introduction

The **AI Story Generator** is a comprehensive application designed to assist authors in creating best-selling novels with engaging plots and logical consistency. It leverages a **Multi-Agent** architecture combined with **Monte Carlo Tree Search (MCTS)** for plot optimization, and uses **RAG (Retrieval-Augmented Generation)** with **ChromaDB** to maintain long-term memory of characters, events, and foreshadowing. It also integrates **ScrapingDog** for real-time information retrieval to ensure story authenticity.

## âœ¨ Features

### 1. Multi-Agent System
-   **Story Planner**: Plans the macro story arc, generating outlines and key plot twists.
-   **Chapter Generator**: Writes detailed chapters, focusing on prose and sensory details.
-   **Critic**: Evaluates generated content based on best-seller criteria and provides feedback.
-   **Researcher**: Searches for real-world data to enrich the story background.

### 2. Core Technologies
-   **MCTS Plot Simulation**: Explores various plot directions to select the most compelling narrative path.
-   **Long-term Memory System**:
    -   **Entity Memory**: Tracks status of characters, items, and locations.
    -   **Event Memory**: Records all key plot points.
    -   **Foreshadowing Management**: Tracks unresolved mysteries and prompts their resolution.
-   **Multi-Model Support**: Compatible with OpenAI API format (GPT-4, Claude, Gemini, DeepSeek, etc.).

### 3. Modern Frontend
-   **Next.js Interface**: Responsive design for an immersive writing experience.
-   **Visual Outline**: Real-time visualization of the story structure.

## ğŸš€ Deployment Guide

### Prerequisites
-   **LLM API Key** (OpenAI, DeepSeek, etc.)
-   **ScrapingDog API Key** (Optional, for research features)

### Method 1: Docker Deployment (Recommended)

1.  **Install Docker**: Ensure Docker and Docker Compose are installed on your system.
2.  **Configure Environment**:
    Create a `.env` file in the `backend` directory:
    ```env
    LLM_API_KEY=sk-your-key
    LLM_BASE_URL=https://api.openai.com/v1
    LLM_MODEL=gpt-4o
    SCRAPINGDOG_API_KEY=your-key
    ```
3.  **Run**:
    ```bash
    docker-compose up --build -d
    ```
4.  **Access**:
    -   Frontend: `http://localhost:3000`
    -   Backend API: `http://localhost:8000/docs`

### Method 2: Source Code Deployment

1.  **Backend**:
    ```bash
    cd backend
    pip install -r requirements.txt
    # Set env vars: LLM_API_KEY, etc.
    uvicorn app.main:app --reload
    ```
2.  **Frontend**:
    ```bash
    cd frontend/frontend
    npm install
    npm run dev
    ```

---

<a name="chinese"></a>
## ğŸ“– é¡¹ç›®ç®€ä»‹

**AI çˆ†æ¬¾å°è¯´ç”Ÿæˆå™¨** æ˜¯ä¸€ä¸ªåŸºäº Multi-Agent æ¶æ„çš„ AI åº”ç”¨ï¼Œæ—¨åœ¨è‡ªåŠ¨åˆ›ä½œæƒ…èŠ‚è·Œå®•èµ·ä¼ã€é€»è¾‘ä¸¥å¯†çš„é•¿çŸ­ç¯‡å°è¯´ã€‚ç³»ç»Ÿç»“åˆäº† **Monte Carlo Tree Search (MCTS)** ç®—æ³•è¿›è¡Œå‰§æƒ…æ¨æ¼”ï¼Œåˆ©ç”¨ **RAG (Retrieval-Augmented Generation)** å’Œ **å‘é‡æ•°æ®åº“ (ChromaDB)** å®ç°é•¿ç¯‡å°è¯´çš„é•¿æœŸè®°å¿†å’Œä¼ç¬”ç®¡ç†ï¼Œå¹¶é›†æˆ **ScrapingDog** è¿›è¡Œå®æ—¶ä¿¡æ¯æ£€ç´¢ã€‚

## âœ¨ æ ¸å¿ƒåŠŸèƒ½

### 1. å¤šæ™ºèƒ½ä½“æ¶æ„ (Multi-Agent System)
-   **Story Planner (å‰§æƒ…ç­–åˆ’)**: è´Ÿè´£å®è§‚æ•…äº‹çº¿çš„è§„åˆ’ï¼Œç”Ÿæˆå¤§çº²å’Œå…³é”®è½¬æŠ˜ç‚¹ã€‚
-   **Chapter Generator (ç« èŠ‚å†™ä½œ)**: è´Ÿè´£å…·ä½“ç« èŠ‚çš„æå†™ï¼Œæ³¨é‡æ–‡ç¬”å’Œç”»é¢æ„Ÿã€‚
-   **Critic (è¯„è®ºå®¶)**: åŸºäºç•…é”€ä¹¦æ ‡å‡†å¯¹ç”Ÿæˆçš„å†…å®¹è¿›è¡Œè¯„åˆ†å’Œåé¦ˆã€‚
-   **Researcher (ç ”ç©¶å‘˜)**: è°ƒç”¨å¤–éƒ¨å·¥å…·æœç´¢èµ„æ–™ï¼Œç¡®ä¿æ•…äº‹èƒŒæ™¯çš„çœŸå®æ€§ã€‚

### 2. æ ¸å¿ƒæŠ€æœ¯
-   **MCTS å‰§æƒ…æ¨æ¼”**: ä½¿ç”¨è’™ç‰¹å¡æ´›æœç´¢æ ‘æ¢ç´¢ä¸åŒçš„å‰§æƒ…èµ°å‘ï¼Œé€‰æ‹©æœ€ä¼˜ã€æœ€å¸å¼•äººçš„æƒ…èŠ‚åˆ†æ”¯ã€‚
-   **é•¿æœŸè®°å¿†ç³»ç»Ÿ (Long-term Memory)**:
    -   **å®ä½“è®°å¿†**: è¿½è¸ªäººç‰©çŠ¶æ€ã€ç‰©å“å½’å±ã€åœ°ç‚¹å˜åŒ–ã€‚
    -   **äº‹ä»¶è®°å¿†**: è®°å½•å‘ç”Ÿè¿‡çš„æ‰€æœ‰å…³é”®æƒ…èŠ‚ã€‚
    -   **ä¼ç¬”ç®¡ç†**: è‡ªåŠ¨è®°å½•æœªè§£ä¹‹è°œï¼Œå¹¶åœ¨åç»­æƒ…èŠ‚ä¸­æç¤ºå›æ”¶ã€‚
-   **å¤šæ¨¡å‹æ”¯æŒ**: å…¼å®¹ OpenAI API æ ¼å¼ï¼Œæ”¯æŒåˆ‡æ¢ GPT-4, Claude, Gemini, DeepSeek ç­‰æ¨¡å‹ã€‚

### 3. ç°ä»£åŒ–å‰ç«¯
-   **Next.js ç•Œé¢**: å“åº”å¼è®¾è®¡ï¼Œæä¾›æ²‰æµ¸å¼çš„å†™ä½œå’Œé˜…è¯»ä½“éªŒã€‚
-   **å¯è§†åŒ–å¤§çº²**: å®æ—¶å±•ç¤ºæ•…äº‹ç»“æ„å’Œå‰§æƒ…åˆ†æ”¯ã€‚

## ğŸš€ éƒ¨ç½²è¯´æ˜

### å‰ç½®å‡†å¤‡
-   **LLM API Key**: (å¦‚ OpenAI, DeepSeek ç­‰)
-   **ScrapingDog API Key**: (ç”¨äºè”ç½‘æœç´¢ï¼Œå¯é€‰)

### æ–¹å¼ä¸€ï¼šDocker éƒ¨ç½² (æ¨è)

1.  **å®‰è£… Docker**: ç¡®ä¿ç³»ç»Ÿå·²å®‰è£… Docker å’Œ Docker Composeã€‚
2.  **é…ç½®ç¯å¢ƒå˜é‡**:
    åœ¨ `backend` ç›®å½•ä¸‹åˆ›å»º `.env` æ–‡ä»¶ï¼š
    ```env
    LLM_API_KEY=sk-your-key
    LLM_BASE_URL=https://api.openai.com/v1
    LLM_MODEL=gpt-4o
    SCRAPINGDOG_API_KEY=your-key
    ```
3.  **å¯åŠ¨æœåŠ¡**:
    ```bash
    docker-compose up --build -d
    ```
4.  **è®¿é—®**:
    -   å‰ç«¯: `http://localhost:3000`
    -   åç«¯ API: `http://localhost:8000/docs`

### æ–¹å¼äºŒï¼šæºç éƒ¨ç½²

1.  **åç«¯**:
    ```bash
    cd backend
    pip install -r requirements.txt
    # è®¾ç½®ç¯å¢ƒå˜é‡: LLM_API_KEY ç­‰
    uvicorn app.main:app --reload
    ```
2.  **å‰ç«¯**:
    ```bash
    cd frontend/frontend
    npm install
    npm run dev
    ```
